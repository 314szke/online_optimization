%!TEX root = ./main.tex

\begin{abstract}
    Designing online algorithms with machine learning predictions is a recent approach beyond the worst-case paradigm for various practically relevant online problems like scheduling, caching, clustering, and ski rental. While most previous learning-augmented algorithms focus on integrating the predictions of a single oracle,
    we study the design of online algorithms with \emph{multiple} prediction sources (experts). To go beyond the performance guarantee of the popular static best expert in hindsight benchmark, we compare our algorithm to a new benchmark (the linear combination of predictions that change over time).
    We present a competitive algorithm in the new dynamic benchmark for $0$-$1$ online \emph{non-linear} covering with a performance guarantee of $O(\ln(K)) \cdot \frac{\lambda}{(1-\mu\ln(K))}$, where $K$ is the number of experts and $\lambda, \mu$ are parameters of the objective function. In particular, for 
 $0$-$1$ online linear covering problems,  the competitive ratio is $O(\ln(K))$. 
 Our novel approach gives a new perspective on combining several online algorithms in an online manner - a central subject in the online algorithm research community.
\end{abstract}
