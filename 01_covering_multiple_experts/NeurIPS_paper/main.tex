\documentclass{article}

% if you need to pass options to natbib, use, e.g.:
%     \PassOptionsToPackage{numbers, compress}{natbib}
% before loading neurips_2023


% ready for submission
\usepackage[nonatbib]{neurips_2023}


% to compile a preprint version, e.g., for submission to arXiv, add add the
% [preprint] option:
%     \usepackage[preprint]{neurips_2023}


% to compile a camera-ready version, add the [final] option, e.g.:
%     \usepackage[final]{neurips_2023}


% to avoid loading the natbib package, add option nonatbib:
%     \usepackage[nonatbib]{neurips_2023}


\usepackage[utf8]{inputenc} % allow utf-8 input
\usepackage[T1]{fontenc}    % use 8-bit T1 fonts
\usepackage{hyperref}       % hyperlinks
\usepackage{url}            % simple URL typesetting
\usepackage{booktabs}       % professional-quality tables
\usepackage{amsfonts}       % blackboard math symbols
\usepackage{nicefrac}       % compact symbols for 1/2, etc.
\usepackage{microtype}      % microtypography
\usepackage{xcolor}         % colors


%%% Our includes
\usepackage{amsmath}
\usepackage[capitalise,noabbrev]{cleveref}
\usepackage{graphicx}
\usepackage{mdframed}
\usepackage{paralist}
\usepackage{wrapfig}

%%% Our new defines
\newcommand{\vect}[1]{\ensuremath {\mathbf{#1}}}
\newenvironment{proof}{\noindent\emph{Proof\ }}{\hspace*{\fill}$\Box$\medskip}
\newtheorem{theorem}{Theorem}
\newtheorem{lemma}{Lemma}
\newtheorem{corollary}{Corollary}
\newtheorem{claim}{Claim}



\title{Online Covering with Multiple Experts}


% The \author macro works with any number of authors. There are two commands
% used to separate the names and addresses of multiple authors: \And and \AND.
%
% Using \And between authors leaves it to LaTeX to determine where to break the
% lines. Using \AND forces a line break at that point. So, if LaTeX puts 3 of 4
% authors names on the first line, and the last on the second line, try using
% \AND instead of \And before the third author name.


\author{%
  Kevi Enik\H{o}\\
  Nguyễn Kim Thắng\\
  LIG, University Grenoble-Alpes, France\\
}


\begin{document}


\maketitle


\begin{abstract}
    Designing online algorithms with machine learning predictions is a recent technique beyond the worst-case paradigm for various practically relevant online problems (scheduling, caching, clustering, ski rental, etc.). While most previous learning-augmented algorithm approaches focus on integrating the predictions of a single oracle,
    we study the design of online algorithms with \emph{multiple} experts. To go beyond the popular benchmark of a static best expert in hindsight, we propose a new \emph{dynamic} benchmark (linear combinations of predictions that change over time).
    We present a competitive algorithm in the new dynamic benchmark with a performance guarantee of $O(\log K)$, where $K$ is the number of experts,
    for $0-1$ online optimization problems. Furthermore, our multiple-expert approach provides a new perspective on how to combine in an online manner several online algorithms - a long-standing central subject in the online algorithm research community.
\end{abstract}

\input{01_introduction}
\input{02_covering}
\input{03_experiments}
\input{04_conclusion}

\bibliographystyle{plainurl}
\bibliography{../paper/references}

%%
% Supplementary part
%%
\newpage
%
\begin{center}
\rule{\textwidth}{.5pt} \\[3pt]
\textbf{\large Supplementary Material} \\[7pt]
\textbf{\large Online Covering with Multiple Experts}
\rule{\textwidth}{.5pt}
\end{center}

%
\appendix
%
\input{05_appendix}
\input{06_counter_example}
\input{07_complete_proofs}

\end{document}
