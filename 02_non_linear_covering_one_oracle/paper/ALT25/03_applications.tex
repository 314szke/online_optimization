%!TEX root = ./main.tex

\section{Applications}	\label{sec:app}
\setcounter{theorem}{0}

To apply Theorem~\ref{thm:covering-formal} on specific problems, we need to determine the local-smoothness parameters for the multilinear extension.
\cite{Thang20:Online-Primal-Dual} provided these parameters for some broad classes of functions, in particular for polynomials with non-negative coefficients. Let $g_{\ell}: \mathbb{R} \rightarrow \mathbb{R}$ for $1 \leq \ell \leq L$
be degree-$k$ polynomials with non-negative coefficients and let $f:~\{0,1\}^{n}~\rightarrow~\mathbb{R}^{+}$ be the cost function
defined as $f(\one_{S}) = \sum_{\ell} b_{\ell} g_{\ell}\bigl( \sum_{e \in S} a_{e} \bigr)$ where $a_{e} \geq 0$ for every
$e$ and $b_{\ell} \geq 0$ for every $1 \leq \ell \leq L$.
Then the multilinear extension $F$ of $f$ is $(O(k \ln(d/\eta))^{k-1}, \frac{k-1}{k \ln(1 + 2d^{2}/\eta)})$-locally smooth.
We will use these parameters to derive the guarantees for the following problems.

\subsection{Load Balancing}

Load balancing is a classic problem in discrete optimization with wide-ranging applications (for example, resource management in data centres).
This problem revolves around assigning jobs that arrive online to $m$ available unrelated machines while minimizing their maximum load.
Each arriving job $j$ reveals its machine dependent execution time $p_{ij}$ where $i \in \{1, m\}$ is the machine's index. The load $\ell_{i}$ of machine $i$ is the total processing time of the jobs assigned
to it. This load balancing problem is a well understood standard online problem and it has a tight competitive ratio of $\Theta(\log m)$ \citep{BorodinEl-Yaniv05:Online-computation,Caragiannis08:Better-bounds}.

In our online setting with predictions, the jobs not only arrive with their machine dependent execution time $p_{ij}$, but their machine dependent prediction as well. Formally, $x_{ij} \in \{0,1\}$ indicates whether job $j$ is assigned to machine $i$, and the oracle provides $pred(x_{ij}) \in \{0,1\}$. We can formulate the online load balancing problem as a non-linear program. The objective is $\min \max_{i=1}^{m} \ell_{i} = \min \max_{i=1}^{m} \bigl(\sum_{j} p_{ij} x_{ij}\bigr)$, and the constraint is $\sum_{i=1}^{m} x_{ij} = 1$ which guarantees that each job $j$ is assigned to some machine $i$. Applying our framework for non-linear programs with covering constraints, Proposition~\ref{prop:load} follows.

\begin{proposition} \label{prop:load}
Algorithm~\ref{algo:covering} gives a
$O(\frac{1}{1 - \eta})$-consistent and $O\bigl((\log m) \log^{2} \frac{m}{\eta}\bigr)$-robust fractional solution
for the load balancing problem. (Proof in \cref{sec:appix-proofs}.)
\end{proposition}

\subsection{Energy Minimization in Scheduling}		\label{sec:energy}

Reducing carbon emissions is a global effort in which energy-efficient algorithms play an essential role. For example, \cite{Albers10:Energy-efficient-algorithms} and \cite{GuCaiZengZhangJinDai:2019} studied energy-efficient algorithms for scheduling.

Given $m$ unrelated machines, we need to assign jobs that arrive online. Each job $j$ has a release date $r_{j}$, a deadline $d_{j}$, and a vector of machine dependent processing times $p_{ij}$. Contrary to performance-oriented scheduling, our goal is to design an assignment policy which can minimize the total energy consumption of the execution. To achieve this, we can adjust the machines' speed $s_{ij}(t)$ during the time interval $[t,t+1)$ for the execution of job $j$. Every machine $i$ has a non-decreasing energy power function $P_{i}(\cdot)$. Typically, $P_{i}(z) = z^{k_{i}}$ for some constant $k_{i} \geq 1$. The execution's total energy is $\sum_{i} \sum_{t} P(\sum_{j} s_{ij}(t))$.

In the classic online setting, this problem is well understood: there exists an $O(k^{k})$-competitive algorithm \citep{Thang20:Online-Primal-Dual} where $k = \max_{i} \{k_{i}\}$
and this bound is tight up to a constant factor \citep{Caragiannis08:Better-bounds}. In our extended study with predictions we represent this problem with the following non-linear program. The objective is $\min \sum_{i} \sum_{t} P(\sum_{j} s_{ij}(t))$ and the constraints are:
$$
\sum_{i=1}^{m} x_{ij} = 1,  \qquad \qquad \sum_{t = r_{j}}^{d_{j}-1} s_{ij}(t) \geq p_{ij} x_{ij}, \qquad  \qquad s_{ij}(t) \geq 0  \qquad \forall\ i,\ t
$$
where $x_{ij} \in \{0,1\}$ indicates whether job $j$ is assigned to machine $i$
and $s_{ij}(t) \geq 0$ denotes the speed of machine $i$ executing job $j$ during the time interval $[t, t+1)$.
The first constraint guarantees that job $j$ is assigned to some machine, and the second one ensures
that the job $j$ is completed on time (on the machine where the job is assigned). At the arrival of
job $j$, the prediction provides a solution $pred(x_{ij})$ and a speed $pred(s_{ij}(t))$ for $r_{j} \leq t \leq d_{j} - 1$.

\begin{proposition}
Algorithm~\ref{algo:covering} gives a
$O(\frac{1}{1 - \eta})$-consistent and $O\bigl(k^{k} \log^{k} \frac{m}{\eta}\bigr)$-robust fractional solution
for the energy minimization problem. (Proof in \cref{sec:appix-proofs}.)
\end{proposition}


\subsection{Online Submodular Mimimization}	\label{sec:sub-min}

Submodular minimization is a widespread subject in optimization and machine learning \citep{IwataFleischer01:A-combinatorial-strongly,Bachothers13:Learning-with,Bach16:Submodular-functions:,BalkanskiSinger:2020}. Let us consider the problem of minimizing an online monotone submodular function subject to covering constraints.
A set-function $f: 2^{\mathcal{E}} \rightarrow \mathbb{R}+$ is \emph{submodular} if
$f(S \cup e) - f(S) \geq f(T \cup e) - f(T)$ for all $S \subset T \subseteq \mathcal{E}$.
Let $F$ be the multilinear extension of a monotone submodular function $f$. Function $F$
admits two useful properties. First, if $f$ is monotone, then so is $F$. Second, $F$ is concave in
the positive direction, meaning that $\nabla F(\vect{x}) \geq \nabla F(\vect{y})$ for all $\vect{x} \leq \vect{y}$, where $\vect{x} \leq \vect{y}$ is defined as $x_{e} \leq y_{e} ~\forall e$.

To apply Algorithm~\ref{algo:covering}, we need to determine the local-smoothness parameters.
An important concept in studying submodular functions is the \emph{curvature}. Given a submodular
function $f$, the \emph{total curvature} $\kappa_{f}$ \citep{ConfortiCornuejols84:Submodular-set-functions} of $f$ is defined as
$
\kappa_{f} = 1 - \min_{e} \frac{f(\one_{\mathcal{E}}) - f(\one_{\mathcal{E} \setminus \{e\}})}{f(\one_{\{e\}})}.
$
Intuitively, the total curvature measures how far away $f$ is from being \emph{modular}. This concept of
curvature is used to determine both upper and lower bounds on the approximation ratios
for many submodular and learning problems \citep{ConfortiCornuejols84:Submodular-set-functions,GoemansHarvey09:Approximating-submodular,BalcanHarvey12:Learning-Submodular,Vondrak10:Submodularity-and-Curvature:,IyerJegelka13:Curvature-and-optimal,SviridenkoVondrak17:Optimal-approximation}.

\begin{proposition}
Algorithm~\ref{algo:covering} gives a
$O(\frac{1}{1 - \eta})$-consistent and $O\bigl( \frac{\log (d/\eta)}{1 - \kappa_{f}} \bigr)$-robust fractional  solution
for the submodular minimization under covering constraints. (Proof in \cref{sec:appix-proofs}.)
\end{proposition}
